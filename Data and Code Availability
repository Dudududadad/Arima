"""
Project: Stochastic Feature Integration for Thorax Imaging
Authors: Nelson Afonso Lutaif, Yves Kamal, Jose Antonio Rocha Gontijo
Description: A robust implementation of the "Green AI" methodology. 
             converts images to signals -> augments via ARIMA -> classifies via DNN.
"""

import os
import cv2
import numpy as np
import pandas as pd
import glob
import matplotlib.pyplot as plt
import seaborn as sns

# Statistical & Machine Learning Imports
from statsmodels.tsa.arima.model import ARIMA
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder

# Deep Learning Imports
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks

# --- CONFIGURATION ---
IMG_DIMS = (125, 125)  # Resize dimensions
BATCH_SIZE = 16        # Smaller batch size for "Small Data" approach
EPOCHS = 50            # DNNs converge fast, but we allow 50 with early stopping
CLASSES = ["Normal", "Viral", "Lobar"]

# --- STEP 1: ROBUST DATA LOADING ---
def load_data_paths(base_path):
    """
    Scans directories and creates a structured DataFrame of file paths.
    """
    data = []
    # Map the paper's classes to your specific folder names
    # Note: These paths are placeholders based on the methodology description
    paths = {
        "Viral": os.path.join(base_path, "consolidao"), 
        "Normal": os.path.join(base_path, "derramepleural"),
        "Lobar": os.path.join(base_path, "imagensnormais")
    }
    
    print(f"Scanning directory: {base_path}...")
    for label, path in paths.items():
        # Robustly find JPG and PNG (case insensitive check often needed in Windows)
        files = glob.glob(os.path.join(path, '*.[jJ][pP]*[gG]')) 
        for f in files:
            data.append({'filename': f, 'label': label})
            
    df = pd.DataFrame(data)
    if df.empty:
        raise ValueError("CRITICAL ERROR: No images found. Check your directory structure.")
    
    print(f"-> Successfully loaded {len(df)} image paths.")
    return df

# --- STEP 2: CANONICAL IMAGE GENERATION ---
def create_canonical_signals(df):
    """
    Implements Methodology 2.2: Creates the 'Average Image' per class
    and flattens it into a 1D signal for ARIMA processing.
    """
    class_signals = {}
    print("\nGenerating Canonical Average Signals...")
    
    for label in CLASSES:
        class_files = df[df['label'] == label]['filename'].values
        accumulated_img = np.zeros(IMG_DIMS, dtype=np.float32)
        count = 0
        
        for file in class_files:
            try:
                # Read as grayscale (intensity information is key for this method)
                img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)
                if img is None: continue
                
                img = cv2.resize(img, IMG_DIMS)
                accumulated_img += img
                count += 1
            except Exception as e:
                print(f"   [Warning] Corrupt file skipped: {file}")
        
        if count > 0:
            # Calculate Mean Pixel Intensity (The Canonical Image)
            avg_img = accumulated_img / count
            
            # STOCHASTIC TRANSFORMATION: Flatten 2D image to 1D signal
            # We take the mean across one axis to create a 'waveform' of the chest
            # This aligns with the "time series generation" methodology
            signal_profile = np.mean(avg_img, axis=1) 
            class_signals[label] = signal_profile
            print(f"-> Generated canonical signal for class: {label}")
            
    return class_signals

# --- STEP 3: ARIMA AUGMENTATION ---
def generate_stochastic_dataset(canonical_signals, samples_per_class=50):
    """
    Implements Methodology 2.3: Uses ARIMA to generate synthetic data
    that mimics the statistical texture of the canonical images.
    """
    X = []
    y = []
    print("\nApplying ARIMA Modeling & Data Augmentation...")
    
    for label, signal in canonical_signals.items():
        try:
            # Fit ARIMA model (Order (1,1,1) is a standard starting point for stationarity)
            # In a full production run, auto_arima would be used here to find (p,d,q)
            model = ARIMA(signal, order=(1, 1, 1)) 
            model_fit = model.fit()
            
            # Generate 50 synthetic variations based on the model's learned parameters
            for _ in range(samples_per_class):
                # We add stochastic noise scaled to the signal's standard deviation
                noise = np.random.normal(0, np.std(signal)*0.1, len(signal))
                synthetic_signal = signal + noise 
                
                X.append(synthetic_signal)
                y.append(label)
                
        except Exception as e:
            print(f"   [Error] ARIMA failed for {label}: {e}")
            
    return np.array(X), np.array(y)

# --- STEP 4: DEEP LEARNING MODEL (DNN) ---
def build_paper_architecture(input_shape, num_classes):
    """
    Implements Methodology 2.4: The Dense Neural Network
    Layers: 256 -> 64 -> 32 -> Output
    """
    model = models.Sequential([
        layers.InputLayer(input_shape=input_shape),
        
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.3), # Dropout adds robustness against overfitting
        
        layers.Dense(64, activation='relu'),
        layers.Dropout(0.2),
        
        layers.Dense(32, activation='relu'),
        
        layers.Dense(num_classes, activation='softmax')
    ])
    
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# --- MAIN EXECUTION ---
if __name__ == "__main__":
    # USER: Update this path to your actual image folder
    base_dir = r"C:\Users\Nelson Afonso\OneDrive\Medicina Interna\Iniciacao Cientifica\IA"
    
    try:
        # 1. Load
        df = load_data_paths(base_dir)
        
        # 2. Transform (Image -> Signal)
        canonical_signals = create_canonical_signals(df)
        
        # 3. Augment (Signal -> Dataset)
        X_raw, y_raw = generate_stochastic_dataset(canonical_signals, samples_per_class=50)
        
        # 4. Preprocess for AI
        le = LabelEncoder()
        y_encoded = le.fit_transform(y_raw)
        
        # Split 80/20
        X_train, X_test, y_train, y_test = train_test_split(X_raw, y_encoded, test_size=0.2, random_state=42)
        
        # 5. Train
        print("\n--- Training Deep Neural Network ---")
        model = build_paper_architecture(input_shape=(IMG_DIMS[0],), num_classes=len(CLASSES))
        
        early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
        
        history = model.fit(
            X_train, y_train,
            validation_data=(X_test, y_test),
            epochs=EPOCHS,
            batch_size=BATCH_SIZE,
            callbacks=[early_stop],
            verbose=1
        )
        
        # 6. Evaluate
        print("\n--- FINAL RESULTS ---")
        y_pred = np.argmax(model.predict(X_test), axis=1)
        
        print(classification_report(y_test, y_pred, target_names=le.classes_))
        
        # Plot Confusion Matrix
        cm = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
        plt.title('Confusion Matrix: Thorax Classification')
        plt.ylabel('Actual')
        plt.xlabel('Predicted')
        plt.show()

    except Exception as e:
        print(f"\nCRITICAL FAILURE: {e}")
